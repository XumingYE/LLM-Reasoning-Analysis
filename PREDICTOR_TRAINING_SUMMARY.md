
# `counts` 值预测器训练总结

本文档详细记录了为预测 `counts` 值（代表模型思考单元个数）而进行的一系列模型训练实验。我们探索了从大型语言模型到小型BERT模型的多种方案，并尝试了回归与分类两种不同的任务范式。

## 1. 初步尝试：大型语言模型 (LLM)

-   **目标**: 使用一个1.5B参数的语言模型 (`DeepSeek-R1-Distill-Qwen-1.5B`) 作为基础，直接进行微调。
-   **过程**: 
    1.  编写了标准的 `transformers` 训练脚本。
    2.  在训练启动后，立即遇到了 `CUDA out of memory` 错误，表明模型对于当前硬件环境来说过大。
    3.  尝试了多种显存优化技术，包括减小批次大小、梯度累积，乃至 `accelerate` + DeepSpeed，但均因显存耗尽而失败。
-   **结论**: 在当前硬件限制下，直接微调1.5B参数规模的模型不可行。必须转向更轻量级的模型方案。

---

## 2. 方案切换：基于 BERT 的预测器

我们选择了一个更经典且轻量级的方案：使用 `bert-base-uncased` (约110M参数) 作为基础模型，并在其上添加一个预测头。

### 2.1 回归模型 (Regression Model)

-   **方法**: 将任务定义为回归问题，直接预测 `counts` 的具体数值。
-   **模型**: `BertForSequenceClassification` 配置为回归模式 (`num_labels=1`)。
-   **评估结果**: 均方误差 (MSE) 约为 **899.07**。
-   **分析与结论**: 模型建立了一个初步的基线，但较高的误差表明精确预测 `counts` 值具有挑战性。这个结果启发我们将问题简化为分类任务。
-   **脚本**: `scripts/train_predictor.py`
-   **模型路径**: `predictor_model/`

### 2.2 分类模型 (Classification Models)

我们将任务转化为预测 `counts` 所属的**区间（类别）**，而不是精确数值。

#### a) 等宽分箱 (Equal-Width Binning)

-   **方法**: 使用 `pd.cut` 将 `counts` 的整体数值范围 (1-456) 均匀地切分为 10 个宽度相同的区间（如 Class 0: 1-46, Class 1: 47-92, ...）。
-   **数据分布**: 极不均衡。超过 **85%** 的样本落入了第一个区间。
-   **评估结果**: 
    -   准确率 (Accuracy): **~84.9%**
    -   宏平均F1分数 (Macro F1-Score): **~0.13**
-   **分析与结论**: **高准确率具有欺骗性**。模型几乎总是预测样本量最大的“类别0”，从而轻易获得高分。极低的F1分数暴露了它几乎完全丧失了识别稀有、高 `counts` 区间的能力。**此方法不适用于构建一个均衡的预测器。**
-   **模型路径**: `predictor_classifier_model_equal_width/`

#### b) 等频分箱 (Equal-Frequency / Quantile Binning)

-   **方法**: 使用 `pd.qcut` 将数据分为8个区间，目标是让**每个区间包含的样本数量大致相等**。
-   **数据分布**: 样本分布均衡，但每个区间的 `counts` 范围宽度不一（如 Class 0: 1-3, Class 7: 56-456）。
-   **评估结果**: 
    -   准确率 (Accuracy): **~33.0%**
    -   宏平均F1分数 (Macro F1-Score): **~0.22**
-   **分析与结论**: 虽然准确率远低于等宽分箱模型，但这是一个**更健康、更有意义的结果**。相对更高的F1分数表明，模型在所有8个类别上都具备了一定的、更均衡的识别能力。它没有只“猜测”样本量大的类别，而是真正地在学习区分不同的思考复杂度。**此方法是后续优化的更优基础。**
-   **模型路径**: `predictor_classifier_model/`

#### c) 两阶段微调 (Two-Stage Fine-Tuning)

-   **方法**: 基于“等频分箱”策略，采用更高级的微调技术。
    1.  **阶段一**: 冻结BERT主干，仅训练分类头，使其初步适应数据。
    2.  **阶段二**: 解冻整个模型，以更小的学习率进行整体微调。
-   **评估结果**: 
    -   准确率 (Accuracy): **~33.0%**
    -   宏平均F1分数 (Macro F1-Score): **~0.195**
-   **分析与结论**: 最终性能与单阶段的等频分箱模型非常接近。这表明对于当前任务和模型规模，两阶段训练并未带来显著优势，但它验证了一种更稳健的训练范式。最终得到的模型同样是一个均衡的、有实际学习能力的模型。
-   **模型路径**: `predictor_staged_classifier_model/`

---

## 最终结论

1.  **模型选择**: 对于当前硬件环境，轻量级的 `bert-base-uncased` 是比1.5B参数大模型更现实、更可行的选择。
2.  **任务范式**: 将 `counts` 预测从**回归任务转化为分类任务**是更有效、更容易获得有意义结果的途径。
3.  **分箱策略**: **等频分箱 (Quantile Binning) 是最优策略**。尽管其准确率数值较低，但它避免了数据不均衡陷阱，训练出的模型F1分数更高，泛化能力更强，是唯一真正学会了识别不同复杂度区间的模型。
