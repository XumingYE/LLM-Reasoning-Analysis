# LLMæ¨ç†å¤æ‚åº¦é¢„æµ‹ - æ‰€æœ‰å®éªŒæ–¹æ³•å¯¹æ¯”

æœ¬æ–‡æ¡£æ±‡æ€»äº†æ‰€æœ‰åœ¨è¯¥é¡¹ç›®ä¸­å°è¯•è¿‡çš„æ¨¡å‹è®­ç»ƒæ–¹æ³•ï¼ŒåŒ…æ‹¬æ–¹æ³•æè¿°ã€ä»»åŠ¡ç±»å‹ã€æŸå¤±å‡½æ•°ã€æ ‡ç­¾æ„å»ºç­–ç•¥ã€æ¨¡å‹æ¶æ„å’Œæ€§èƒ½ç»“æœã€‚

---

## ğŸ“Š å®éªŒæ–¹æ³•å¯¹æ¯”æ€»è¡¨

| # | æ–¹æ³•åç§° | ä»»åŠ¡ç±»å‹ | æŸå¤±å‡½æ•° | æ•°æ®é›†æ ‡ç­¾æ„å»º | åŸºç¡€æ¨¡å‹ | æœ€ä½³æŒ‡æ ‡ | å¤‡æ³¨ |
|---|---------|---------|---------|--------------|---------|---------|------|
| 1 | **åŸºç¡€å›å½’æ¨¡å‹** | å›å½’ | MSE | ç›´æ¥ä½¿ç”¨countså€¼ | BERT-base-uncased (110M) | MSE: 899.07 | åŸºçº¿æ¨¡å‹ï¼Œè¯¯å·®è¾ƒå¤§ |
| 2 | **ç­‰å®½åˆ†ç®±åˆ†ç±»å™¨** | åˆ†ç±» (10ç±») | CrossEntropy | ç­‰å®½åˆ†ç®± (pd.cut)<br>Bin 0: 1-46, Bin 1: 47-92... | BERT-base-uncased | Acc: 84.9%<br>**F1-macro: 0.13** | âŒ æ•°æ®ä¸¥é‡ä¸å‡è¡¡ï¼Œæ¨¡å‹åªé¢„æµ‹Bin 0 |
| 3 | **ç­‰é¢‘åˆ†ç®±åˆ†ç±»å™¨** | åˆ†ç±» (8ç±») | CrossEntropy | ç­‰é¢‘åˆ†ç®± (pd.qcut)<br>æ¯ä¸ªbinæ ·æœ¬é‡ç›¸è¿‘ | BERT-base-uncased | Acc: 33.0%<br>**F1-macro: 0.22** | âœ… è¾ƒå‡è¡¡ï¼Œä½†æ€§èƒ½ä»æœ‰é™ |
| 4 | **ä¸¤é˜¶æ®µå¾®è°ƒåˆ†ç±»å™¨** | åˆ†ç±» (10ç±») | CrossEntropy | ç­‰é¢‘åˆ†ç®± (pd.qcut) | BERT-base-uncased | Acc: 33.0%<br>**F1-macro: 0.195** | é˜¶æ®µ1å†»ç»“BERTï¼Œé˜¶æ®µ2å…¨é‡å¾®è°ƒ |
| 5 | **æ‰‹åŠ¨åˆ†ç®±å›å½’å™¨** | å›å½’ | MSE | æ‰‹åŠ¨å®šä¹‰10ä¸ªbin<br>é¢„æµ‹binç´¢å¼•ä½œä¸ºè¿ç»­å€¼ | BERT-base-uncased | **MAE: 1.13** | é¢„æµ‹binç´¢å¼•è€Œécountså€¼ |
| 6 | **åŠ æƒåˆ†ç±»å™¨ (æ‰‹åŠ¨10 bins)** | åˆ†ç±» (10ç±») | Weighted CrossEntropy | æ‰‹åŠ¨åˆ†ç®±<br>Bin edges: [0,1,4,8,17,28,41,66,98,200,1000] | BERT-base-uncased | Acc: 44.4%<br>**F1-macro: 19.6%** | âš ï¸ ä½¿ç”¨class weightså¤„ç†ä¸å‡è¡¡<br>3ä¸ªbinçš„F1=0% |
| 7 | **è‡ªå®šä¹‰RoBERTaåˆ†ç±»å™¨** | åˆ†ç±» (10ç±») | Weighted CrossEntropy | æ‰‹åŠ¨åˆ†ç®± (åŒæ–¹æ³•6) | RoBERTa-large (355M)<br>å†»ç»“åº•å±‚+è‡ªå®šä¹‰åˆ†ç±»å¤´ | è®­ç»ƒä¸­ (æœªå®Œæˆ) | ä½¿ç”¨æ›´å¤§æ¨¡å‹ + è‡ªå®šä¹‰åˆ†ç±»å¤´ |
| 8 | **DeBERTa + ç‰¹å¾å·¥ç¨‹** | åˆ†ç±» (10ç±») | Weighted CrossEntropy | æ‰‹åŠ¨åˆ†ç®± (åŒæ–¹æ³•6)<br>**+ ç‰¹å¾å·¥ç¨‹æ ‡è®°** | DeBERTa-v3-large (435M) | Acc: 44.4%<br>**F1-macro: 19.6%** | æ·»åŠ [EXPLAIN], [CREATIVE]ç­‰ç‰¹å¾æ ‡è®°<br>æ€§èƒ½ä¸æ–¹æ³•6ç›¸åŒ |
| 9 | **K-meansèšç±»åˆ†ç±»å™¨ (å«å¼‚å¸¸å€¼)** | åˆ†ç±» (10ç±») | Weighted CrossEntropy | K-meansèšç±»<br>åŸºäºcountsã€è¯æ•°ç­‰ç‰¹å¾<br>**æœªè¿‡æ»¤å¼‚å¸¸å€¼** | DeBERTa-v3-large (435M) | ä¸è¯¦ | âŒ Label 6ä»…219æ ·æœ¬ï¼ŒcountsèŒƒå›´133-943<br>æ•°æ®ä¸å‡è¡¡ |
| 10 | **ğŸ† K-meansèšç±»åˆ†ç±»å™¨ (Clean)** | åˆ†ç±» (8ç±») | Weighted CrossEntropy | K-meansèšç±»<br>**è¿‡æ»¤å¼‚å¸¸å€¼ (counts>130)**<br>40,526æ ·æœ¬ | DeBERTa-v3-large (435M) | **Acc: 99.04%**<br>**F1-macro: 97.89%** | âœ… **æœ€ä½³æ–¹æ³•ï¼**<br>æ‰€æœ‰label F1 > 88%<br>å‘ç°è¯­ä¹‰ä»»åŠ¡ç±»å‹ |
| 11 | **DeBERTa å›å½’æ¨¡å‹ (Wait Only)** | å›å½’ | MSE | ç›´æ¥ä½¿ç”¨countså€¼ | DeBERTa-v3-base | MAE: 1.05<br>MSE: 6.19 | é’ˆå¯¹Wait Onlyæ•°æ®è®­ç»ƒ |
| 12 | **DeBERTa åˆ†ç±»æ¨¡å‹ (Wait Only)** | åˆ†ç±» (6ç±») | Weighted CrossEntropy | æ‰‹åŠ¨åˆ†ç®± (1,2,3,4,5-8,>8) | DeBERTa-v3-base | Acc: 44.47%<br>**F1-macro: 0.280** | é’ˆå¯¹Wait Onlyæ•°æ®è®­ç»ƒï¼Œä½¿ç”¨class weights |

---

## ğŸ“ è¯¦ç»†æ–¹æ³•è¯´æ˜

### æ–¹æ³• 1: åŸºç¡€å›å½’æ¨¡å‹
**è„šæœ¬**: `scripts/training/train_predictor.py`
**æ¨¡å‹è·¯å¾„**: `predictor_model/`

- **ä»»åŠ¡å®šä¹‰**: ç›´æ¥é¢„æµ‹countsçš„å…·ä½“æ•°å€¼ï¼ˆ1-943ï¼‰
- **æ¨¡å‹é…ç½®**: `AutoModelForSequenceClassification` with `num_labels=1`
- **æŸå¤±å‡½æ•°**: MSE (Mean Squared Error)
- **è®­ç»ƒé…ç½®**:
  - Epochs: 3
  - Batch size: 8
  - Learning rate: 2e-5
  - Metric: MSE, MAE

**ç»“æœåˆ†æ**:
- MSE: 899.07 (è¾ƒé«˜)
- è¯´æ˜ç²¾ç¡®é¢„æµ‹countså€¼å›°éš¾ï¼Œå¯å‘åç»­è½¬å‘åˆ†ç±»ä»»åŠ¡

---

### æ–¹æ³• 2: ç­‰å®½åˆ†ç®±åˆ†ç±»å™¨
**è„šæœ¬**: `scripts/training/train_classifier.py`
**æ¨¡å‹è·¯å¾„**: `predictor_classifier_model_equal_width/`

- **æ ‡ç­¾æ„å»º**: ä½¿ç”¨ `pd.cut()` å°†countsèŒƒå›´(1-456)ç­‰åˆ†ä¸º10ä¸ªåŒºé—´
  - Bin 0: 1-46
  - Bin 1: 47-92
  - ...
  - Bin 9: 409-456
- **æ•°æ®åˆ†å¸ƒ**: **ä¸¥é‡ä¸å‡è¡¡** - 85%æ ·æœ¬åœ¨Bin 0
- **æŸå¤±å‡½æ•°**: CrossEntropy

**ç»“æœåˆ†æ**:
- Accuracy: 84.9% (æ¬ºéª—æ€§é«˜)
- **F1-macro: 0.13** (æä½)
- âŒ **å¤±è´¥åŸå› **: æ¨¡å‹å‡ ä¹åªé¢„æµ‹Bin 0ï¼Œæ— æ³•è¯†åˆ«ç¨€æœ‰é«˜complexityç±»åˆ«

---

### æ–¹æ³• 3: ç­‰é¢‘åˆ†ç®±åˆ†ç±»å™¨
**è„šæœ¬**: `scripts/training/train_classifier.py`
**æ¨¡å‹è·¯å¾„**: `predictor_classifier_model/`

- **æ ‡ç­¾æ„å»º**: ä½¿ç”¨ `pd.qcut()` åˆ›å»º8ä¸ªæ ·æœ¬é‡å¤§è‡´ç›¸ç­‰çš„åŒºé—´
  - Bin 0: counts 1-3
  - Bin 7: counts 56-456
- **æ•°æ®åˆ†å¸ƒ**: æ¯ä¸ªbinæ ·æœ¬é‡ç›¸è¿‘
- **æŸå¤±å‡½æ•°**: CrossEntropy

**ç»“æœåˆ†æ**:
- Accuracy: 33.0%
- **F1-macro: 0.22**
- âœ… æ¯”ç­‰å®½åˆ†ç®±å¥åº·ï¼Œæ¨¡å‹åœ¨æ‰€æœ‰ç±»åˆ«éƒ½æœ‰è¯†åˆ«èƒ½åŠ›

---

### æ–¹æ³• 4: ä¸¤é˜¶æ®µå¾®è°ƒåˆ†ç±»å™¨
**è„šæœ¬**: `scripts/training/train_staged_classifier.py`
**æ¨¡å‹è·¯å¾„**: `predictor_staged_classifier_model/`

- **æ ‡ç­¾æ„å»º**: ç­‰é¢‘åˆ†ç®± (åŒæ–¹æ³•3)
- **è®­ç»ƒç­–ç•¥**:
  - **Stage 1**: å†»ç»“BERTä¸»å¹²ï¼Œåªè®­ç»ƒåˆ†ç±»å¤´ (lr=5e-4, epochs=2)
  - **Stage 2**: è§£å†»å…¨éƒ¨å‚æ•°ï¼Œä½å­¦ä¹ ç‡å¾®è°ƒ (lr=2e-5, epochs=2)
- **æŸå¤±å‡½æ•°**: CrossEntropy

**ç»“æœåˆ†æ**:
- Accuracy: 33.0%
- F1-macro: 0.195
- ä¸å•é˜¶æ®µæ€§èƒ½æ¥è¿‘ï¼Œæœªå¸¦æ¥æ˜¾è‘—æå‡

---

### æ–¹æ³• 5: æ‰‹åŠ¨åˆ†ç®±å›å½’å™¨
**è„šæœ¬**: `scripts/training/train_regressor_on_bins.py`
**æ¨¡å‹è·¯å¾„**: `predictor_regressor_model_manual_10_bins/`

- **æ ‡ç­¾æ„å»º**: æ‰‹åŠ¨å®šä¹‰10ä¸ªbinï¼Œä½†å°†binç´¢å¼•ä½œä¸ºè¿ç»­å€¼è¿›è¡Œå›å½’
  - Bin edges: [0,1,8,16,25,35,56,81,140,239,3000]
- **æŸå¤±å‡½æ•°**: MSE (é¢„æµ‹binç´¢å¼•0-9çš„æµ®ç‚¹å€¼)
- **åˆ›æ–°ç‚¹**: å…è®¸æŸå¤±å‡½æ•°æƒ©ç½šè·ç¦»çœŸå®binè¾ƒè¿œçš„é¢„æµ‹

**ç»“æœåˆ†æ**:
- **MAE: 1.13** (å¹³å‡åç¦»1.13ä¸ªbin)
- æ¯”ç›´æ¥å›å½’countsæ•ˆæœå¥½ï¼Œä½†ä»æœªè§£å†³ç±»åˆ«ä¸å‡è¡¡é—®é¢˜

---

### æ–¹æ³• 6: åŠ æƒåˆ†ç±»å™¨ (æ‰‹åŠ¨10 bins)
**è„šæœ¬**: `scripts/training/train_weighted_classifier.py`
**æ¨¡å‹è·¯å¾„**: `predictor_weighted_classifier_manual_10_bins/`

- **æ ‡ç­¾æ„å»º**: æ‰‹åŠ¨ä¼˜åŒ–çš„10ä¸ªbin
  ```python
  bin_edges = [0, 1, 4, 8, 17, 28, 41, 66, 98, 200, 1000]
  ```
  - Bin 0-2: ç®€å•æŸ¥è¯¢ (counts 1-8)
  - Bin 3-6: ä¸­ç­‰å¤æ‚åº¦ (counts 9-66)
  - Bin 7-9: é«˜å¤æ‚åº¦ (counts 67+)

- **æŸå¤±å‡½æ•°**: **Weighted CrossEntropy**
  - ä½¿ç”¨ `sklearn.utils.class_weight.compute_class_weight('balanced')`
  - è‡ªå®šä¹‰ `WeightedTrainer` è¦†ç›– `compute_loss()`

- **æ•°æ®åˆ†å¸ƒ**:
  - Bin 0: 44.89% (18,205æ ·æœ¬)
  - Bin 9: 0.31% (125æ ·æœ¬)

**ç»“æœåˆ†æ**:
- Accuracy: 44.4%
- **F1-macro: 19.6%**
- **å¤±è´¥åŸå› **:
  - 3ä¸ªbinçš„F1=0% (Bin 1, 7, 9)
  - æœ€å°binä»…12ä¸ªæµ‹è¯•æ ·æœ¬
  - å¼‚å¸¸å€¼æ±¡æŸ“ (236æ ·æœ¬counts>130)

---

### æ–¹æ³• 7: è‡ªå®šä¹‰RoBERTaåˆ†ç±»å™¨
**è„šæœ¬**: `scripts/training/train_custom_roberta.py`
**æ¨¡å‹è·¯å¾„**: `custom_roberta_weighted_classifier/`

- **æ¨¡å‹æ¶æ„**:
  - åŸºç¡€: RoBERTa-large (355Må‚æ•°)
  - **å†»ç»“**: é™¤æœ€å2å±‚å¤–çš„æ‰€æœ‰å±‚
  - **è‡ªå®šä¹‰åˆ†ç±»å¤´**:
    ```python
    nn.Linear(hidden_size, 512) -> GELU -> Dropout(0.2) -> nn.Linear(512, num_labels)
    ```

- **æ ‡ç­¾æ„å»º**: æ‰‹åŠ¨10 bins (åŒæ–¹æ³•6)
- **æŸå¤±å‡½æ•°**: Weighted CrossEntropy
- **è®­ç»ƒé…ç½®**:
  - Epochs: 5
  - Batch size: 4
  - Learning rate: 5e-5

**ç»“æœåˆ†æ**:
- è®­ç»ƒæœªå®Œæˆ / æ•ˆæœä¸è¯¦
- å°è¯•é€šè¿‡æ›´å¤§æ¨¡å‹å’Œè‡ªå®šä¹‰åˆ†ç±»å¤´æå‡æ€§èƒ½

---

### æ–¹æ³• 8: DeBERTa + ç‰¹å¾å·¥ç¨‹
**è„šæœ¬**: `scripts/training/train_deberta_with_features.py`
**æ¨¡å‹è·¯å¾„**: `predictor_deberta_large_with_features/`

- **æ¨¡å‹**: DeBERTa-v3-large (435Må‚æ•°)
- **æ ‡ç­¾æ„å»º**: æ‰‹åŠ¨10 bins (åŒæ–¹æ³•6)
- **æŸå¤±å‡½æ•°**: Weighted CrossEntropy

- **ç‰¹å¾å·¥ç¨‹** (æ ¸å¿ƒåˆ›æ–°):
  ```python
  # é•¿åº¦æ ‡è®°
  [SHORT] / [MEDIUM] / [LONG]

  # ä»»åŠ¡ç±»å‹æ ‡è®°
  [EXPLAIN] - explain, describe, analyze, compare
  [CREATIVE] - write, create, generate, story
  [CALCULATE] - calculate, compute, solve
  [LIST] - list, enumerate, identify

  # å¤æ‚åº¦æ ‡è®°
  [COMPARE], [CONDITIONAL], [MULTI_Q], [WHY], [HOW]
  ```
  - ç‰¹å¾æ ‡è®°å‰ç½®äºåŸå§‹æ–‡æœ¬

**ç»“æœåˆ†æ**:
- Accuracy: 44.4%
- **F1-macro: 19.6%**
- ä¸æ–¹æ³•6æ€§èƒ½ç›¸åŒï¼Œè¯´æ˜**ç‰¹å¾å·¥ç¨‹æœªè§£å†³æ ¹æœ¬é—®é¢˜** (æ•°æ®åˆ†å¸ƒä¸å‡è¡¡)

---

### æ–¹æ³• 9: K-meansèšç±»åˆ†ç±»å™¨ (å«å¼‚å¸¸å€¼)
**è„šæœ¬**: `scripts/analysis/discover_clusters.py`
**æ¨¡å‹è·¯å¾„**: (è®­ç»ƒè¢«ä¸­æ­¢)

- **æ ‡ç­¾æ„å»ºæ–¹æ³•**:
  - åŸºäºcountsã€word_countã€char_countç­‰ç‰¹å¾è¿›è¡ŒK-meansèšç±»
  - ç‰¹å¾æ ‡å‡†åŒ– (StandardScaler)
  - æµ‹è¯•K=4-10ï¼Œé€‰æ‹©K=10

- **é—®é¢˜**:
  - âŒ **æœªè¿‡æ»¤å¼‚å¸¸å€¼** (236æ ·æœ¬counts>130)
  - Label 6: ä»…219æ ·æœ¬ï¼ŒcountsèŒƒå›´133-943
  - å¯¼è‡´ä¸¥é‡ä¸å‡è¡¡

**ç»“æœåˆ†æ**:
- å‘ç°é—®é¢˜åç«‹å³åœæ­¢ï¼Œè½¬å‘æ–¹æ³•10

---

### æ–¹æ³• 10: ğŸ† K-meansèšç±»åˆ†ç±»å™¨ (Clean) - **æœ€ä½³æ–¹æ³•**
**è„šæœ¬**: `scripts/analysis/discover_clusters_clean.py` + `scripts/training/train_deberta_clusters_clean.py`
**æ¨¡å‹è·¯å¾„**: `predictor_deberta_clusters_clean/`
**é…ç½®æ–‡ä»¶**: `data/cluster_config_clean.json`
**æ•°æ®é›†**: `data/merged_with_clusters_clean.jsonl`

#### æ•°æ®å‡†å¤‡
1. **å¼‚å¸¸å€¼è¿‡æ»¤**: ç§»é™¤counts>130çš„æ ·æœ¬ (236ä¸ª, 0.6%)
2. **ç‰¹å¾æå–**:
   ```python
   ['counts', 'word_count', 'char_count', 'question_marks',
    'has_explain', 'has_creative', 'has_calculate', 'has_list',
    'has_why', 'has_how']
   ```
3. **K-meansèšç±»**: æµ‹è¯•K=4-8ï¼Œé€‰æ‹©K=8
   - Silhouette score: 0.5384
   - Balance score: 1.056 (vs 1.202 for æ–¹æ³•6)
4. **æ ‡ç­¾æ˜ å°„**: æŒ‰å¹³å‡countsæ’åºï¼Œæ˜ å°„ä¸ºLabel 0-7

#### å‘ç°çš„è¯­ä¹‰èšç±»

| Label | ä»»åŠ¡ç±»å‹ | å¤æ‚åº¦ | å¹³å‡Counts | æ ·æœ¬é‡ | ç‰¹å¾ |
|-------|---------|-------|-----------|-------|------|
| 0 | General | Simple | 9.6 | 3,223 (7.95%) | ç®€å•åˆ—è¡¨ã€åˆ†ç±» |
| 1 | Explanation | Simple | 9.8 | 907 (2.24%) | ç®€å•"Why"é—®é¢˜ |
| 2 | Explanation | Moderate | 10.7 | 5,178 (12.78%) | 100% explainå…³é”®è¯ |
| 3 | General | Moderate | 11.0 | 3,347 (8.26%) | ä¸€èˆ¬é—®ç­” |
| 4 | General | Moderate | 11.4 | 16,471 (40.64%) | ä¸€èˆ¬ä»»åŠ¡ |
| 5 | Creative | Moderate | 12.0 | 9,069 (22.38%) | 100% creativeå…³é”®è¯ |
| 6 | Coding/Calc | Complex | 15.0 | 1,297 (3.20%) | 100% calculateå…³é”®è¯ |
| 7 | Long-form | Complex | 16.9 | 1,034 (2.55%) | é•¿æ–‡æœ¬åˆ†æã€æ€»ç»“ |
### æ–¹æ³• 11: DeBERTa å›å½’æ¨¡å‹ (Wait Only)
**è„šæœ¬**: `scripts/training/train_deberta_regressor_wait_only.py`
**æ¨¡å‹è·¯å¾„**: `predictor_deberta_regressor_wait_only/`

- **ä»»åŠ¡å®šä¹‰**: ç›´æ¥é¢„æµ‹countsçš„å…·ä½“æ•°å€¼
- **æ¨¡å‹é…ç½®**: `AutoModelForSequenceClassification` with `num_labels=1`
- **æŸå¤±å‡½æ•°**: MSE (Mean Squared Error)
- **è®­ç»ƒé…ç½®**:
  - Epochs: 3
  - Batch size: 8
  - Learning rate: 2e-5
  - Metric: MSE, MAE

**æ€§èƒ½ç»“æœ**:

```json
{
    "eval_loss": 0.1715116798877716,
    "eval_mse": 6.193479537963867,
    "eval_mae": 1.0496591329574585,
    "eval_runtime": 33.0522,
    "eval_samples_per_second": 119.175,
    "eval_steps_per_second": 7.473,
    "epoch": 3.0
}
```

---

### æ–¹æ³• 12: DeBERTa åˆ†ç±»æ¨¡å‹ (Wait Only)
**è„šæœ¬**: `scripts/training/train_deberta_classifier_wait_only.py`
**æ¨¡å‹è·¯å¾„**: `predictor_deberta_classifier_wait_only/`

- **ä»»åŠ¡å®šä¹‰**: é¢„æµ‹countsæ‰€å±çš„6ä¸ªç±»åˆ«
- **æ ‡ç­¾æ„å»º**: æ‰‹åŠ¨åˆ†ç®±
  - Bin 0: counts = 1
  - Bin 1: counts = 2
  - Bin 2: counts = 3
  - Bin 3: counts = 4
  - Bin 4: counts = 5-8
  - Bin 5: counts > 8
- **æŸå¤±å‡½æ•°**: Weighted CrossEntropy
- **è®­ç»ƒé…ç½®**:
  - Epochs: 5
  - Batch size: 8
  - Learning rate: 2e-5
  - Metric: Accuracy, F1-macro

**æ€§èƒ½ç»“æœ**:

```json
{
    "eval_loss": 1.6463533639907837,
    "eval_accuracy": 0.4446897228354182,
    "eval_f1_macro": 0.2797250791323674,
    "eval_runtime": 33.8616,
    "eval_samples_per_second": 120.402,
    "eval_steps_per_second": 7.531,
    "epoch": 5.0
}
```

#### æ¨¡å‹è®­ç»ƒ
- **æ¨¡å‹**: DeBERTa-v3-large (435M)
- **ç‰¹å¾å·¥ç¨‹**: åŒæ–¹æ³•8çš„ç‰¹å¾æ ‡è®°
- **æŸå¤±å‡½æ•°**: Weighted CrossEntropy
- **è®­ç»ƒé…ç½®**:
  - Epochs: 5
  - Batch size: 2
  - Learning rate: 1e-5
  - Gradient accumulation: 2

#### ğŸ† æ€§èƒ½ç»“æœ (evaluation_results.json)

```json
{
  "eval_accuracy": 0.9904 (99.04%),
  "eval_f1_macro": 0.9789 (97.89%),
  "eval_f1_label_0": 0.8807 (88.07%),
  "eval_f1_label_1": 0.9933 (99.33%),
  "eval_f1_label_2": 0.9952 (99.52%),
  "eval_f1_label_3": 0.9945 (99.45%),
  "eval_f1_label_4": 1.0000 (100.00%) â­,
  "eval_f1_label_5": 0.9922 (99.22%),
  "eval_f1_label_6": 0.9910 (99.10%),
  "eval_f1_label_7": 0.9846 (98.46%),
  "eval_loss": 0.0695
}
```

#### âœ… æˆåŠŸå…³é”®å› ç´ 

1. **èŒƒå¼è½¬å˜**: ä»é¢„æµ‹counts â†’ é¢„æµ‹è¯­ä¹‰ä»»åŠ¡ç±»å‹
2. **æ•°æ®æ¸…æ´—**: ç§»é™¤å¼‚å¸¸å€¼ï¼Œé¿å…å™ªå£°
3. **å‡è¡¡åˆ†å¸ƒ**: æœ€å°labelæœ‰90ä¸ªæµ‹è¯•æ ·æœ¬ (vs æ–¹æ³•6çš„12ä¸ª)
4. **è¯­ä¹‰å‘ç°**: K-meansè‡ªåŠ¨å‘ç°äº†ä»»åŠ¡ç±»å‹çš„è‡ªç„¶èšç±»
   - Label 2: 100% explanationä»»åŠ¡
   - Label 5: 100% creativeä»»åŠ¡
   - Label 6: 100% coding/calculationä»»åŠ¡
5. **ç‰¹å¾å·¥ç¨‹**: ç‰¹å¾æ ‡è®°å¸®åŠ©æ¨¡å‹è¯†åˆ«ä»»åŠ¡ç±»å‹

#### å¯¹æ¯”æ”¹è¿›

| æŒ‡æ ‡ | æ–¹æ³•6 (æ‰‹åŠ¨bins) | æ–¹æ³•10 (èšç±») | æ”¹è¿› |
|-----|-----------------|--------------|------|
| **F1-macro** | 19.6% | **97.89%** | **+78.3%** |
| **Accuracy** | 44.4% | **99.04%** | **+54.6%** |
| **å¤±è´¥labels** | 3ä¸ª (F1=0%) | **0ä¸ª** | âœ… |
| **æœ€ä½F1** | 0.00% | **88.07%** | âœ… |
| **è®­ç»ƒæ—¶é•¿** | ~3å°æ—¶ | ~6å°æ—¶ | å¯æ¥å— |

---

## ğŸ¯ æ ¸å¿ƒå‘ç°ä¸æ€»ç»“

### å¤±è´¥çš„æ–¹æ³•
1. **ç­‰å®½åˆ†ç®±** (æ–¹æ³•2): æ•°æ®åˆ†å¸ƒæåº¦ä¸å‡ â†’ æ¨¡å‹åªå­¦ä¼šé¢„æµ‹ä¸»æµç±»åˆ«
2. **æ‰‹åŠ¨åˆ†ç®±** (æ–¹æ³•6, 8): åŸºäºcountsèŒƒå›´çš„ä»»æ„åˆ’åˆ† â†’ æ··åˆäº†ä¸åŒè¯­ä¹‰ç±»å‹
3. **å¤§æ¨¡å‹å°è¯•** (æ–¹æ³•7): è®¡ç®—èµ„æºé™åˆ¶ï¼Œæœªå®Œæˆè®­ç»ƒ

### æˆåŠŸçš„æ–¹æ³•
- **K-meansèšç±»** (æ–¹æ³•10):
  - å‘ç°æ•°æ®çš„è‡ªç„¶è¯­ä¹‰ç»“æ„
  - ä»»åŠ¡ç±»å‹ (explanation, creative, coding) + å¤æ‚åº¦å±‚çº§
  - æ•°æ®é©±åŠ¨è€Œéäººå·¥è§„åˆ™

### å…³é”®æ•™è®­
1. **é—®é¢˜é‡æ„æ¯”ä¼˜åŒ–æ¨¡å‹æ›´é‡è¦**:
   - âŒ "é¢„æµ‹ç²¾ç¡®countså€¼" â†’ å›°éš¾ä¸”æ— å®ç”¨ä»·å€¼
   - âœ… "é¢„æµ‹ä»»åŠ¡ç±»å‹+å¤æ‚åº¦å±‚çº§" â†’ é«˜ç²¾åº¦ä¸”å®ç”¨

2. **æ•°æ®åˆ†å¸ƒå†³å®šæˆè´¥**:
   - å¼‚å¸¸å€¼ (0.6%æ•°æ®) ä¸¥é‡æ±¡æŸ“è®­ç»ƒ
   - æœ€å°ç±»åˆ«éœ€è¦è¶³å¤Ÿæ ·æœ¬ (è‡³å°‘90+æµ‹è¯•æ ·æœ¬)

3. **ç‰¹å¾å·¥ç¨‹éœ€é…åˆæ­£ç¡®çš„ä»»åŠ¡å®šä¹‰**:
   - æ–¹æ³•8: ç‰¹å¾å·¥ç¨‹ + é”™è¯¯binning â†’ æ— æ•ˆ
   - æ–¹æ³•10: ç‰¹å¾å·¥ç¨‹ + è¯­ä¹‰èšç±» â†’ å®Œç¾é…åˆ

### å®é™…åº”ç”¨ä»·å€¼
æ–¹æ³•10ä¸ä»…é¢„æµ‹å‡†ç¡®ï¼Œè¿˜å…·æœ‰å®é™…æ„ä¹‰ï¼š
- **ä»»åŠ¡è·¯ç”±**: æ ¹æ®ç±»å‹åˆ†é…åˆ°ä¸åŒpipeline (analytical/creative/code)
- **èµ„æºåˆ†é…**: æ ¹æ®å¤æ‚åº¦åˆ†é…è®¡ç®—èµ„æº
- **è´¨é‡æ§åˆ¶**: æ£€æµ‹å¼‚å¸¸å¤æ‚çš„å“åº”

---

## ğŸ“ ç›¸å…³æ–‡ä»¶ç´¢å¼•

### è®­ç»ƒè„šæœ¬
- `scripts/training/train_predictor.py` - æ–¹æ³•1
- `scripts/training/train_classifier.py` - æ–¹æ³•2, 3
- `scripts/training/train_staged_classifier.py` - æ–¹æ³•4
- `scripts/training/train_regressor_on_bins.py` - æ–¹æ³•5
- `scripts/training/train_weighted_classifier.py` - æ–¹æ³•6
- `scripts/training/train_custom_roberta.py` - æ–¹æ³•7
- `scripts/training/train_deberta_with_features.py` - æ–¹æ³•8
- `scripts/training/train_deberta_clusters_clean.py` - æ–¹æ³•10

### æ•°æ®å¤„ç†
- `scripts/analysis/discover_clusters.py` - æ–¹æ³•9 èšç±»
- `scripts/analysis/discover_clusters_clean.py` - æ–¹æ³•10 æ¸…æ´—èšç±»
- `scripts/data_processing/add_counts_field.py` - countsè®¡ç®—

### æ¨ç†ä¸è¯„ä¼°
- `scripts/run_inference.py` - åŸºç¡€æ¨ç†
- `scripts/run_weighted_classifier_inference.py` - åŠ æƒåˆ†ç±»å™¨æ¨ç†
- `scripts/run_cluster_inference.py` - èšç±»æ¨¡å‹æ¨ç†
- `example_usage.py` - ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ç¤ºä¾‹

### æ–‡æ¡£
- `PREDICTOR_TRAINING_SUMMARY.md` - æ—©æœŸè®­ç»ƒæ€»ç»“
- `FINAL_SUMMARY.md` - æœ€ç»ˆé¡¹ç›®æ€»ç»“
- `CLAUDE.md` - é¡¹ç›®ä½¿ç”¨æŒ‡å—
- `ALL_EXPERIMENTS_COMPARISON.md` - æœ¬æ–‡æ¡£

---

**æœ€åæ›´æ–°**: 2025-10-22
**æœ€ä½³æ–¹æ³•**: æ–¹æ³•10 - K-meansèšç±»åˆ†ç±»å™¨ (Clean)
**æœ€ä½³F1-macro**: 97.89%
**è®­ç»ƒæ€»æ—¶é•¿**: çº¦30å°æ—¶ (æ‰€æœ‰æ–¹æ³•ç´¯è®¡)
