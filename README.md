# 2025年10月17日

## 项目目标

本项目旨在分析用户查询（Query）、模型生成内容（Content）以及模型思维链（CoT）复杂度（以`counts`字段量化）三者之间的关系，并基于此训练一个预测模型。

## 已完成工作

1.  **数据处理与分析**:
    *   新增了 `counts` 字段以量化思维链的复杂度。
    *   对数据进行了可视化分析，并识别出四种主要的噪音模式：“重复指令噪音”、“内容错位噪音”、“循环思考噪音”和“模型拒绝噪音”。
    *   相关脚本和样本文件已归档。

## 预测器训练 (Predictor Training)

我们尝试了两种不同的方法来训练一个模型，该模型根据用户问题（`instruction` + `input`）来预测 `counts` 的值。

### 1. 回归模型 (Regression Model)

-   **方法**: 使用 `bert-base-uncased` 作为基础模型，添加一个回归头，直接预测 `counts` 的数值。
-   **评估结果**: 最终模型的均方误差 (MSE) 约为 `899.07`。
-   **结论**: 模型建立了一个初步的基线，但较高的误差表明精确预测 `counts` 值具有挑战性。
-   **脚本**: `scripts/train_predictor.py`
-   **模型路径**: `predictor_model/`

### 2. 分类模型 (Classification Models)

为了探索另一种可能性，我们将回归问题转化为分类问题，通过对 `counts` 值进行分箱来预测其所属的区间。

#### 2.1 等频分箱 (Equal Frequency / Quantile Binning)

-   **方法**: 使用 `pd.qcut` 将 `counts` 值分为 8 个区间，确保每个区间包含大致相等数量的样本。
-   **分箱结果**: 区间分布不均，低 `counts` 值的区间范围很窄，高 `counts` 值的区间范围很宽（例如，Class 0: 1-3, Class 7: 56-456）。
-   **评估结果**: 准确率约为 **33%**，宏平均 F1 分数约为 **0.22**。
-   **结论**: 准确率虽然不高（随机猜测为12.5%），但相对均衡的 F1 分数表明，模型对所有类别都有一定的学习能力，更适合用于识别不同复杂度的任务，包括高 `counts` 的情况。
-   **模型路径**: `predictor_classifier_model/`

#### 2.2 等宽分箱 (Equal Width Binning)

-   **方法**: 按照用户的要求，使用 `pd.cut` 将 `counts` 的整个数值范围（1-456）均匀地切分为 10 个宽度相同的区间。
-   **分箱结果**: 区间宽度均匀（例如，Class 0: 1-46, Class 1: 47-92, ...）。然而，样本分布极不均衡，超过85%的样本落入第一个区间。
-   **评估结果**: 准确率高达 **84.9%**，但宏平均 F1 分数仅为 **0.13**。
-   **结论**: 高准确率具有欺骗性。模型主要通过预测绝大多数样本所属的“类别0”来获得高分，但极低的 F1 分数表明，它几乎完全丧失了识别高 `counts` 区间的能力。这种方法不适合于识别稀有但重要的复杂任务。
-   **模型路径**: `predictor_classifier_model_equal_width/`

### 总结

对于预测 `counts` 的任务，直接的回归和简单的分类都面临挑战。**等频分箱（Quantile Binning）** 的分类方法在模型的泛化能力和识别不同复杂度任务方面表现更优，是未来进一步优化的更好基础。

## 生成文件列表

*   `scripts/add_counts_field.py`: 用于计算 `counts` 字段的脚本。
*   `scripts/analyze_data.py`: 用于数据分析和可视化的脚本。
*   `scripts/train_predictor.py`: 用于训练回归预测器的脚本。
*   `scripts/train_classifier.py`: 用于训练分类预测器的脚本。
*   `predictor_model/`: 回归预测器模型。
*   `predictor_classifier_model/`: 等频分箱的分类预测器模型。
*   `predictor_classifier_model_equal_width/`: 等宽分箱的分类预测器模型。

---

### 实验: 基于等频分箱的回归模型 (2025-10-20)

**目标:**

本次实验旨在探索一种新方法, 将“思考轮次”(`counts`)预测任务构建为一个回归问题. 核心思路是: 首先使用等频分箱(Equal-Frequency Binning)将`counts`值划分到不同的区间(bin), 然后训练一个回归模型来预测这些区间的*索引号*. 这种方法的好处是, 模型的损失函数能够惩罚那些与真实区间相差较远的预测 (例如, 对于真实标签为4的样本, 预测为1的惩罚会比预测为3更大), 从而抓取到任务的次序性(ordinal)特征.

**方法论:**

1.  **脚本:** 创建了一个新的训练脚本 `scripts/training/train_regressor_on_bins.py`.
2.  **数据处理:**
    *   使用 `data/merged_with_labels_and_counts.jsonl` 文件中的 `counts` 字段作为预测目标.
    *   使用 `pandas.qcut` 进行等频(分位数)分箱. 修复了一个因数据分布问题导致 `qcut` 产生的实际分箱数少于请求数时脚本出错的bug.
3.  **模型:**
    *   基础模型为 `bert-base-uncased`.
    *   通过设置 `num_labels=1`, 将 `AutoModelForSequenceClassification` 配置为回归模型.
    *   模型被训练来预测分箱区间的索引号(一个浮点数).

**执行过程:**

我们尝试让模型创建8个分箱区间. 由于数据分布的原因, 最终实际创建了5个分箱.

```bash
python scripts/training/train_regressor_on_bins.py --num_bins 8
```

**结果:**

经过3个epoch的训练, 模型在测试集上的最终评估指标如下:

*   **均方误差 (MSE):** `2.297`
*   **平均绝对误差 (MAE):** `1.130`

**分析:**

约等于1.13的MAE指标说明, 模型的预测结果平均偏离了约1个分箱区间. 这表明模型成功学习到了`counts`数据的整体趋势 (例如, 能够区分低、中、高`counts`的样本).

然而, 模型的精度依然有限. 一个分箱区间的误差可能非常显著, 特别是考虑到每个分箱内部包含的`counts`值范围大小不一且跨度很大. 总之, 这个方法是一个可行的起点, 但需要进一步优化以提升准确率.
