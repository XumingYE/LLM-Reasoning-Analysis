# 2025年10月17日

## 项目目标

本项目旨在分析用户查询（Query）、模型生成内容（Content）以及模型思维链（CoT）复杂度（以`counts`字段量化）三者之间的关系，并基于此训练一个预测模型。

## 已完成工作

1.  **数据处理与分析**:
    *   新增了 `counts` 字段以量化思维链的复杂度。
    *   对数据进行了可视化分析，并识别出四种主要的噪音模式：“重复指令噪音”、“内容错位噪音”、“循环思考噪音”和“模型拒绝噪音”。
    *   相关脚本和样本文件已归档。

## 预测器训练 (Predictor Training)

我们尝试了两种不同的方法来训练一个模型，该模型根据用户问题（`instruction` + `input`）来预测 `counts` 的值。

### 1. 回归模型 (Regression Model)

-   **方法**: 使用 `bert-base-uncased` 作为基础模型，添加一个回归头，直接预测 `counts` 的数值。
-   **评估结果**: 最终模型的均方误差 (MSE) 约为 `899.07`。
-   **结论**: 模型建立了一个初步的基线，但较高的误差表明精确预测 `counts` 值具有挑战性。
-   **脚本**: `scripts/train_predictor.py`
-   **模型路径**: `predictor_model/`

### 2. 分类模型 (Classification Models)

为了探索另一种可能性，我们将回归问题转化为分类问题，通过对 `counts` 值进行分箱来预测其所属的区间。

#### 2.1 等频分箱 (Equal Frequency / Quantile Binning)

-   **方法**: 使用 `pd.qcut` 将 `counts` 值分为 8 个区间，确保每个区间包含大致相等数量的样本。
-   **分箱结果**: 区间分布不均，低 `counts` 值的区间范围很窄，高 `counts` 值的区间范围很宽（例如，Class 0: 1-3, Class 7: 56-456）。
-   **评估结果**: 准确率约为 **33%**，宏平均 F1 分数约为 **0.22**。
-   **结论**: 准确率虽然不高（随机猜测为12.5%），但相对均衡的 F1 分数表明，模型对所有类别都有一定的学习能力，更适合用于识别不同复杂度的任务，包括高 `counts` 的情况。
-   **模型路径**: `predictor_classifier_model/`

#### 2.2 等宽分箱 (Equal Width Binning)

-   **方法**: 按照用户的要求，使用 `pd.cut` 将 `counts` 的整个数值范围（1-456）均匀地切分为 10 个宽度相同的区间。
-   **分箱结果**: 区间宽度均匀（例如，Class 0: 1-46, Class 1: 47-92, ...）。然而，样本分布极不均衡，超过85%的样本落入第一个区间。
-   **评估结果**: 准确率高达 **84.9%**，但宏平均 F1 分数仅为 **0.13**。
-   **结论**: 高准确率具有欺骗性。模型主要通过预测绝大多数样本所属的“类别0”来获得高分，但极低的 F1 分数表明，它几乎完全丧失了识别高 `counts` 区间的能力。这种方法不适合于识别稀有但重要的复杂任务。
-   **模型路径**: `predictor_classifier_model_equal_width/`

### 总结

对于预测 `counts` 的任务，直接的回归和简单的分类都面临挑战。**等频分箱（Quantile Binning）** 的分类方法在模型的泛化能力和识别不同复杂度任务方面表现更优，是未来进一步优化的更好基础。

## 生成文件列表

*   `scripts/add_counts_field.py`: 用于计算 `counts` 字段的脚本。
*   `scripts/analyze_data.py`: 用于数据分析和可视化的脚本。
*   `scripts/train_predictor.py`: 用于训练回归预测器的脚本。
*   `scripts/train_classifier.py`: 用于训练分类预测器的脚本。
*   `predictor_model/`: 回归预测器模型。
*   `predictor_classifier_model/`: 等频分箱的分类预测器模型。
*   `predictor_classifier_model_equal_width/`: 等宽分箱的分类预测器模型。

---

### 实验: 基于等频分箱的回归模型 (2025-10-20)

**目标:**

本次实验旨在探索一种新方法, 将“思考轮次”(`counts`)预测任务构建为一个回归问题. 核心思路是: 首先使用等频分箱(Equal-Frequency Binning)将`counts`值划分到不同的区间(bin), 然后训练一个回归模型来预测这些区间的*索引号*. 这种方法的好处是, 模型的损失函数能够惩罚那些与真实区间相差较远的预测 (例如, 对于真实标签为4的样本, 预测为1的惩罚会比预测为3更大), 从而抓取到任务的次序性(ordinal)特征.

**方法论:**

1.  **脚本:** 创建了一个新的训练脚本 `scripts/training/train_regressor_on_bins.py`.
2.  **数据处理:**
    *   使用 `data/merged_with_labels_and_counts.jsonl` 文件中的 `counts` 字段作为预测目标.
    *   使用 `pandas.qcut` 进行等频(分位数)分箱. 修复了一个因数据分布问题导致 `qcut` 产生的实际分箱数少于请求数时脚本出错的bug.
3.  **模型:**
    *   基础模型为 `bert-base-uncased`.
    *   通过设置 `num_labels=1`, 将 `AutoModelForSequenceClassification` 配置为回归模型.
    *   模型被训练来预测分箱区间的索引号(一个浮点数).

**执行过程:**

我们尝试让模型创建8个分箱区间. 由于数据分布的原因, 最终实际创建了5个分箱.

```bash
python scripts/training/train_regressor_on_bins.py --num_bins 8
```

**结果:**

经过3个epoch的训练, 模型在测试集上的最终评估指标如下:

*   **均方误差 (MSE):** `2.297`
*   **平均绝对误差 (MAE):** `1.130`

**分析:**

约等于1.13的MAE指标说明, 模型的预测结果平均偏离了约1个分箱区间. 这表明模型成功学习到了`counts`数据的整体趋势 (例如, 能够区分低、中、高`counts`的样本).

然而, 模型的精度依然有限. 一个分箱区间的误差可能非常显著, 特别是考虑到每个分箱内部包含的`counts`值范围大小不一且跨度很大. 总之, 这个方法是一个可行的起点, 但需要进一步优化以提升准确率.

---

# 2025年10月20日：模型迭代与最终方案

今天的工作是整个项目的一个缩影：我们从发现数据问题开始，通过一系列的分析、试错、调试和修正，最终确定了一个更科学、更鲁棒的建模方案。

## 1. 发现并修正数据问题

-   **问题**: 我们首先注意到，用于计算`counts`的脚本`add_counts_field.py`在统计关键词时忽略了大小写 (`re.IGNORECASE`)。这并不合理，因为在思维链中，大写开头的关键词（如`Wait`）通常标志着一个新思考阶段的开始，其意义与句子中间的小写单词（如`wait`）不同。
-   **修正**: 我们移除了忽略大小写的标志，重新生成了`data/merged_with_labels_and_counts.jsonl`文件。新的`counts`值分布更合理，平均值从28下降到12.8，最大值从2333下降到943，为后续建模奠定了坚实基础。

## 2. 探索分箱策略：从自动到手动

-   **背景**: 之前的回归模型（MAE≈1.13）证明了预测`counts`区间的思路可行，但受限于不合理的分箱，效果有限。
-   **尝试1：对数变换**: 我们首先尝试对新的`counts`值进行对数变换(`np.log1p`)，希望以此缓解数据长尾分布，从而让自动等频分箱(`pd.qcut`)能创建出更均衡的区间。**实验失败**，`pd.qcut`依然只能创建5个不均衡的区间，模型性能没有显著提升（MAE≈1.11）。
-   **尝试2：手动分箱**: 既然自动分箱不可行，我们转向手动定义分箱边界。通过`scripts/analysis/analyze_counts_distribution.py`分析了新`counts`的分布后，我们设计了一套10个区间的划分方案，在数据密集的低位区间进行细分，同时保证了高位区间的粒度。

## 3. 最终方案：带权重的分类模型

-   **问题**: 手动分箱虽然合理，但直接用于回归任务会导致性能下降（MAE上升到1.86）。其根本原因是**类别极度不均衡**：超过40%的样本`counts`值为1（属于Bin 0），而最复杂的`Bin 9`样本占比不到0.5%。回归模型的损失函数被海量简单样本主导，放弃了对稀有复杂样本的学习。
-   **最终方案**: 我们将任务重新定义为**带权重的分类任务**。
    1.  **模型**: `AutoModelForSequenceClassification`，`num_labels=10`。
    2.  **分箱**: 采用我们精心设计的10个手动分箱区间。
    3.  **核心：类别权重**: 创建了一个自定义的`WeightedTrainer`，在计算损失时，为样本量少的类别（如`Bin 9`）赋予极高的权重（32.61），为样本量大的类别（如`Bin 0`）赋予极低的权重（0.22）。这等于强制模型关注那些稀有但重要的复杂任务，预测错一个的惩罚远大于预测错一个简单任务。
    4.  **指标**: 重新以**宏平均F1分数（F1-macro）**作为核心评估指标，因为它能公平地评估模型在所有10个类别上的综合性能。

## 4. 训练与结果

-   **脚本**: `scripts/training/train_weighted_classifier.py`
-   **模型路径**: `predictor_weighted_classifier_manual_10_bins/`
-   **过程**: 在经历了多次由于代码和环境问题导致的失败后（最终通过修正代码和升级库解决），我们成功启动了训练。
-   **初步结果 (3 epochs)**: 模型在3个epoch后，F1-macro达到**19.6%**。这个数值本身不高，但它证明了类别加权策略完全奏效，模型已经开始学习所有类别，而不再是只预测简单类别。这是一个非常有价值的、诚实的模型基线。
-   **中断的训练 (5 epochs)**: 为了进一步提升性能，我们尝试将训练增加到5个epoch。训练在第4个epoch左右因磁盘空间不足而中断。但从日志看，损失仍在稳步下降，这表明增加训练时间是有效的。

## 总结与展望

今天的探索是富有成效的。我们不仅修正了数据的根本问题，还通过一系列迭代，找到了应对数据极度不均衡问题的正确方法——**手动分箱 + 带权重的分类**。虽然最终的训练意外中断，但我们已经拥有了一个鲁棒的训练流程和一个有价值的基线模型。下一步，最直接的优化就是清理磁盘空间，让模型完成完整的训练，并可以考虑进一步增加训练轮次。